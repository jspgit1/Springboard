{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several face detection methods. Running on face1\n",
    "import numpy as np\n",
    "import os\n",
    "import face_recognition as frg\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import re\n",
    "import math\n",
    "import mtcnn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "\n",
    "def show_face(img_path, location):\n",
    "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    (top,right, bottom, left) = location\n",
    "\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "    display(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dlib get_frontal_face_detector()\n",
    "\n",
    "import dlib\n",
    "import cv2\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "img_path = 'maskedface/train/00009/002.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = detector(gray, 1) # result\n",
    "#to draw faces on image\n",
    "for result in faces:\n",
    "    left = result.left()\n",
    "    top = result.top()\n",
    "    right = result.right()\n",
    "    bottom = result.bottom()\n",
    "    location = [top,right,bottom, left]\n",
    "    \n",
    "    show_face(img_path, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haar Cascade\n",
    "# https://towardsdatascience.com/face-detection-models-which-to-use-and-why-d263e82c302c\n",
    "\n",
    "import cv2\n",
    "classifier = cv2.CascadeClassifier('models/haarcascade_frontalface_alt2.xml')\n",
    "img_path = 'maskedface/train/00009/001.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "faces = classifier.detectMultiScale(img)# result\n",
    "#to draw faces on image\n",
    "for result in faces:\n",
    "    x, y, w, h = result\n",
    "    location = [y, x+w,y+h, x]\n",
    "    show_face(img_path, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frontal face detector of DNN module\n",
    "# https://towardsdatascience.com/face-detection-models-which-to-use-and-why-d263e82c302c\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "modelFile = \"models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"models/deploy.prototxt.txt\"\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "img = cv2.imread('maskedface/train/00013/004.jpg')\n",
    "h, w = img.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 117.0, 123.0))\n",
    "net.setInput(blob)\n",
    "faces = net.forward()\n",
    "#to draw faces on image\n",
    "for i in range(faces.shape[2]):\n",
    "        confidence = faces[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = faces[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "            location = [y,]\n",
    "            cv2.rectangle(img, (x, y), (x1, y1), (0, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare bounding box from MTCNN and face_recognition\n",
    "filename = 'knn_examples/train/biden/biden.jpg' # filename is defined above, otherwise uncomment\n",
    "# load image from file\n",
    "pixels = plt.imread(filename) # defined above, otherwise uncomment\n",
    "# detector is defined above, otherwise uncomment\n",
    "detector = mtcnn.MTCNN()\n",
    "# detect faces in the image\n",
    "faces = detector.detect_faces(pixels)\n",
    "print('len(faces):',len(faces))\n",
    "for result in faces:\n",
    "    # get coordinates\n",
    "    x, y, w, h = result['box']\n",
    "    print('x, y, w, h:',x, y, w, h)\n",
    "    m_location = [y, x+w,y+h, x]\n",
    "    print('m_locations:',m_location)\n",
    "        \n",
    "f_locations = frg.face_locations(pixels, model='hog')\n",
    "# display faces on the original image\n",
    "\n",
    "print('f_locations:',f_locations)\n",
    "#draw_facebox(filename, faces)\n",
    "show_face(filename, m_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
